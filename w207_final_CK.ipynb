{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data\n",
    "members = pd.read_csv('members_filtered.csv')\n",
    "transactions = pd.read_csv('transactions_filtered.csv')\n",
    "user_logs = pd.read_csv('user_logs_filtered.csv')\n",
    "labels = pd.read_csv('labels_filtered.csv')\n",
    "\n",
    "#Set indices\n",
    "members.set_index('msno', inplace = True)\n",
    "labels.set_index('msno', inplace = True)\n",
    "\n",
    "#user_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pd_to_date(df_col):\n",
    "    df_col = pd.to_datetime(df_col, format = '%Y%m%d')\n",
    "    return df_col\n",
    "\n",
    "#Convert to date\n",
    "user_logs['date'] = pd_to_date(user_logs['date'])\n",
    "#user_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High level plan.  Let's try several things:\n",
    "\n",
    "* Initially get a table by user (1 row per user)\n",
    "* User most recent date (max date)\n",
    "* User first date (min date)\n",
    "* How long they've been listening:  Min vs. max date by user\n",
    "* Matrix of all the following (cartesian product)\n",
    "    * Total X=(seconds, 100, 985, 75, 50, 25, unique), avg per day of X, maybe median per day of X\n",
    "    * Last day, last 7 days, last 30 days, last 90, 180, 365, total (note last day is relative to user)\n",
    "    * % change in periods above vs. outside that period.\n",
    "    * ??? Total change in periods above vs. outside that period.\n",
    "    * ??? Variation (do they listen consistently, or is it varied)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create our groupby user object \n",
    "user_logs_gb = user_logs.groupby(['msno'], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This cell is slow\n",
    "\n",
    "#Append max date to every row in main table\n",
    "user_logs['max_date'] = user_logs_gb['date'].transform('max')\n",
    "user_logs['days_before_max_date'] = (user_logs['max_date'] - user_logs['date']).apply(lambda x: x.days)\n",
    "    #The .apply(lambda...  just converts it from datetime to an integer, for easier comparisons later.\n",
    "\n",
    "#Generate user's first date, last date, and tenure\n",
    "#Also, the user_logs_features table will be the primary table to return from the transactions table\n",
    "user_logs_features = (user_logs_gb\n",
    "    .agg({'date':['max', 'min', lambda x: (max(x) - min(x)).days]})  #.days converts to int\n",
    "    .rename(columns={'max': 'max_date', 'min': 'min_date','<lambda>':'listening_tenure'})\n",
    "                      )\n",
    "#Add a 3rd level, used for joining data later\n",
    "user_logs_features = pd.concat([user_logs_features], axis=1, keys=['date_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">date_features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max_date</th>\n",
       "      <th>min_date</th>\n",
       "      <th>listening_tenure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AtRE9/xHjNrX8tcuUb/cdBRvUHpwXhZrWY9E9sk1tDk=</th>\n",
       "      <td>2017-02-24</td>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3HbYjEEVBVeWcP3FNDCLKJXpuIZPvX0oFyn4XLMN3k=</th>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q7nR6DbodHwUTGPi5Z0yOsdC2cSOhiWIe4cNEVmnJ9I=</th>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>2016-02-07</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qx9cihonlt2hkBa3VHNj+nwX2QelZXpyHnEAIjD199w=</th>\n",
       "      <td>2017-02-24</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mf3zFfyeZLl8zEWhV+GyWQYjt3orfQUCcOIMwBJ60+k=</th>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             date_features             \\\n",
       "                                                      date              \n",
       "                                                  max_date   min_date   \n",
       "msno                                                                    \n",
       "AtRE9/xHjNrX8tcuUb/cdBRvUHpwXhZrWY9E9sk1tDk=    2017-02-24 2016-01-25   \n",
       "f3HbYjEEVBVeWcP3FNDCLKJXpuIZPvX0oFyn4XLMN3k=    2017-02-28 2015-01-02   \n",
       "Q7nR6DbodHwUTGPi5Z0yOsdC2cSOhiWIe4cNEVmnJ9I=    2017-02-28 2016-02-07   \n",
       "Qx9cihonlt2hkBa3VHNj+nwX2QelZXpyHnEAIjD199w=    2017-02-24 2015-01-02   \n",
       "mf3zFfyeZLl8zEWhV+GyWQYjt3orfQUCcOIMwBJ60+k=    2017-02-28 2015-12-20   \n",
       "\n",
       "                                                               \n",
       "                                                               \n",
       "                                             listening_tenure  \n",
       "msno                                                           \n",
       "AtRE9/xHjNrX8tcuUb/cdBRvUHpwXhZrWY9E9sk1tDk=              396  \n",
       "f3HbYjEEVBVeWcP3FNDCLKJXpuIZPvX0oFyn4XLMN3k=              788  \n",
       "Q7nR6DbodHwUTGPi5Z0yOsdC2cSOhiWIe4cNEVmnJ9I=              387  \n",
       "Qx9cihonlt2hkBa3VHNj+nwX2QelZXpyHnEAIjD199w=              784  \n",
       "mf3zFfyeZLl8zEWhV+GyWQYjt3orfQUCcOIMwBJ60+k=              436  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_logs_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Total X=(seconds, 100, 985, 75, 50, 25, unique), avg per day of X, maybe median per day of X\n",
    "# Last day, last 7 days, last 30 days, last 90, 180, 365, total (note last day is relative to user)\n",
    "    \n",
    "for num_days in [7, 14, 31, 90, 180, 365, 999]:\n",
    "    #Create groupby object for items with x days\n",
    "    ul_gb_xdays = (user_logs.loc[(user_logs['days_before_max_date'] < num_days)]\n",
    "                   .groupby(['msno'], sort=False))\n",
    "\n",
    "    #Generate sum and mean (and count, once) for all the user logs stats\n",
    "    past_xdays_by_user = (ul_gb_xdays\n",
    "        .agg({'num_unq':['sum', 'mean', 'count'],\n",
    "              'total_secs':['sum', 'mean'],\n",
    "              'num_25':['sum', 'mean'],\n",
    "              'num_50':['sum', 'mean'],\n",
    "              'num_75':['sum', 'mean'],\n",
    "              'num_985':['sum', 'mean'],\n",
    "              'num_100':['sum', 'mean'],\n",
    "             })\n",
    "                      )\n",
    "    #Append level header\n",
    "    past_xdays_by_user = pd.concat([past_xdays_by_user], axis=1, keys=['within_days_' + str(num_days)])\n",
    "\n",
    "    #Join (append) to user_logs_features table\n",
    "    user_logs_features = user_logs_features.join(past_xdays_by_user, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"15\" halign=\"left\">within_days_999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">num_unq</th>\n",
       "      <th colspan=\"2\" halign=\"left\">total_secs</th>\n",
       "      <th colspan=\"2\" halign=\"left\">num_25</th>\n",
       "      <th colspan=\"2\" halign=\"left\">num_50</th>\n",
       "      <th colspan=\"2\" halign=\"left\">num_75</th>\n",
       "      <th colspan=\"2\" halign=\"left\">num_985</th>\n",
       "      <th colspan=\"2\" halign=\"left\">num_100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AtRE9/xHjNrX8tcuUb/cdBRvUHpwXhZrWY9E9sk1tDk=</th>\n",
       "      <td>4415</td>\n",
       "      <td>26.596386</td>\n",
       "      <td>166</td>\n",
       "      <td>1322731.253</td>\n",
       "      <td>7968.260560</td>\n",
       "      <td>1266</td>\n",
       "      <td>7.626506</td>\n",
       "      <td>373</td>\n",
       "      <td>2.246988</td>\n",
       "      <td>289</td>\n",
       "      <td>1.740964</td>\n",
       "      <td>276</td>\n",
       "      <td>1.662651</td>\n",
       "      <td>4691</td>\n",
       "      <td>28.259036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3HbYjEEVBVeWcP3FNDCLKJXpuIZPvX0oFyn4XLMN3k=</th>\n",
       "      <td>38727</td>\n",
       "      <td>59.763889</td>\n",
       "      <td>648</td>\n",
       "      <td>8907675.813</td>\n",
       "      <td>13746.413292</td>\n",
       "      <td>11151</td>\n",
       "      <td>17.208333</td>\n",
       "      <td>1086</td>\n",
       "      <td>1.675926</td>\n",
       "      <td>644</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>1170</td>\n",
       "      <td>1.805556</td>\n",
       "      <td>34569</td>\n",
       "      <td>53.347222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q7nR6DbodHwUTGPi5Z0yOsdC2cSOhiWIe4cNEVmnJ9I=</th>\n",
       "      <td>5553</td>\n",
       "      <td>21.440154</td>\n",
       "      <td>259</td>\n",
       "      <td>1180378.152</td>\n",
       "      <td>4557.444602</td>\n",
       "      <td>1709</td>\n",
       "      <td>6.598456</td>\n",
       "      <td>465</td>\n",
       "      <td>1.795367</td>\n",
       "      <td>316</td>\n",
       "      <td>1.220077</td>\n",
       "      <td>436</td>\n",
       "      <td>1.683398</td>\n",
       "      <td>4103</td>\n",
       "      <td>15.841699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qx9cihonlt2hkBa3VHNj+nwX2QelZXpyHnEAIjD199w=</th>\n",
       "      <td>24321</td>\n",
       "      <td>40.067545</td>\n",
       "      <td>607</td>\n",
       "      <td>6386130.422</td>\n",
       "      <td>10520.807944</td>\n",
       "      <td>7354</td>\n",
       "      <td>12.115321</td>\n",
       "      <td>1472</td>\n",
       "      <td>2.425041</td>\n",
       "      <td>985</td>\n",
       "      <td>1.622735</td>\n",
       "      <td>915</td>\n",
       "      <td>1.507414</td>\n",
       "      <td>23001</td>\n",
       "      <td>37.892916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mf3zFfyeZLl8zEWhV+GyWQYjt3orfQUCcOIMwBJ60+k=</th>\n",
       "      <td>4768</td>\n",
       "      <td>14.536585</td>\n",
       "      <td>328</td>\n",
       "      <td>1225399.482</td>\n",
       "      <td>3735.974030</td>\n",
       "      <td>1546</td>\n",
       "      <td>4.713415</td>\n",
       "      <td>258</td>\n",
       "      <td>0.786585</td>\n",
       "      <td>175</td>\n",
       "      <td>0.533537</td>\n",
       "      <td>232</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>4874</td>\n",
       "      <td>14.859756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             within_days_999                   \\\n",
       "                                                     num_unq                    \n",
       "                                                         sum       mean count   \n",
       "msno                                                                            \n",
       "AtRE9/xHjNrX8tcuUb/cdBRvUHpwXhZrWY9E9sk1tDk=            4415  26.596386   166   \n",
       "f3HbYjEEVBVeWcP3FNDCLKJXpuIZPvX0oFyn4XLMN3k=           38727  59.763889   648   \n",
       "Q7nR6DbodHwUTGPi5Z0yOsdC2cSOhiWIe4cNEVmnJ9I=            5553  21.440154   259   \n",
       "Qx9cihonlt2hkBa3VHNj+nwX2QelZXpyHnEAIjD199w=           24321  40.067545   607   \n",
       "mf3zFfyeZLl8zEWhV+GyWQYjt3orfQUCcOIMwBJ60+k=            4768  14.536585   328   \n",
       "\n",
       "                                                                         \\\n",
       "                                               total_secs                 \n",
       "                                                      sum          mean   \n",
       "msno                                                                      \n",
       "AtRE9/xHjNrX8tcuUb/cdBRvUHpwXhZrWY9E9sk1tDk=  1322731.253   7968.260560   \n",
       "f3HbYjEEVBVeWcP3FNDCLKJXpuIZPvX0oFyn4XLMN3k=  8907675.813  13746.413292   \n",
       "Q7nR6DbodHwUTGPi5Z0yOsdC2cSOhiWIe4cNEVmnJ9I=  1180378.152   4557.444602   \n",
       "Qx9cihonlt2hkBa3VHNj+nwX2QelZXpyHnEAIjD199w=  6386130.422  10520.807944   \n",
       "mf3zFfyeZLl8zEWhV+GyWQYjt3orfQUCcOIMwBJ60+k=  1225399.482   3735.974030   \n",
       "\n",
       "                                                                       \\\n",
       "                                             num_25            num_50   \n",
       "                                                sum       mean    sum   \n",
       "msno                                                                    \n",
       "AtRE9/xHjNrX8tcuUb/cdBRvUHpwXhZrWY9E9sk1tDk=   1266   7.626506    373   \n",
       "f3HbYjEEVBVeWcP3FNDCLKJXpuIZPvX0oFyn4XLMN3k=  11151  17.208333   1086   \n",
       "Q7nR6DbodHwUTGPi5Z0yOsdC2cSOhiWIe4cNEVmnJ9I=   1709   6.598456    465   \n",
       "Qx9cihonlt2hkBa3VHNj+nwX2QelZXpyHnEAIjD199w=   7354  12.115321   1472   \n",
       "mf3zFfyeZLl8zEWhV+GyWQYjt3orfQUCcOIMwBJ60+k=   1546   4.713415    258   \n",
       "\n",
       "                                                                         \\\n",
       "                                                       num_75             \n",
       "                                                  mean    sum      mean   \n",
       "msno                                                                      \n",
       "AtRE9/xHjNrX8tcuUb/cdBRvUHpwXhZrWY9E9sk1tDk=  2.246988    289  1.740964   \n",
       "f3HbYjEEVBVeWcP3FNDCLKJXpuIZPvX0oFyn4XLMN3k=  1.675926    644  0.993827   \n",
       "Q7nR6DbodHwUTGPi5Z0yOsdC2cSOhiWIe4cNEVmnJ9I=  1.795367    316  1.220077   \n",
       "Qx9cihonlt2hkBa3VHNj+nwX2QelZXpyHnEAIjD199w=  2.425041    985  1.622735   \n",
       "mf3zFfyeZLl8zEWhV+GyWQYjt3orfQUCcOIMwBJ60+k=  0.786585    175  0.533537   \n",
       "\n",
       "                                                                        \\\n",
       "                                             num_985           num_100   \n",
       "                                                 sum      mean     sum   \n",
       "msno                                                                     \n",
       "AtRE9/xHjNrX8tcuUb/cdBRvUHpwXhZrWY9E9sk1tDk=     276  1.662651    4691   \n",
       "f3HbYjEEVBVeWcP3FNDCLKJXpuIZPvX0oFyn4XLMN3k=    1170  1.805556   34569   \n",
       "Q7nR6DbodHwUTGPi5Z0yOsdC2cSOhiWIe4cNEVmnJ9I=     436  1.683398    4103   \n",
       "Qx9cihonlt2hkBa3VHNj+nwX2QelZXpyHnEAIjD199w=     915  1.507414   23001   \n",
       "mf3zFfyeZLl8zEWhV+GyWQYjt3orfQUCcOIMwBJ60+k=     232  0.707317    4874   \n",
       "\n",
       "                                                         \n",
       "                                                         \n",
       "                                                   mean  \n",
       "msno                                                     \n",
       "AtRE9/xHjNrX8tcuUb/cdBRvUHpwXhZrWY9E9sk1tDk=  28.259036  \n",
       "f3HbYjEEVBVeWcP3FNDCLKJXpuIZPvX0oFyn4XLMN3k=  53.347222  \n",
       "Q7nR6DbodHwUTGPi5Z0yOsdC2cSOhiWIe4cNEVmnJ9I=  15.841699  \n",
       "Qx9cihonlt2hkBa3VHNj+nwX2QelZXpyHnEAIjD199w=  37.892916  \n",
       "mf3zFfyeZLl8zEWhV+GyWQYjt3orfQUCcOIMwBJ60+k=  14.859756  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Next, let's look at changes in last 7 days vs. last 30 days, and last 30 days vs. last 180 days.\n",
    "\n",
    "#Also, need to think about users with < x days tenure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save to CSV\n",
    "#Now skipping this step in favor of writing the full features table to CSV below\n",
    "#user_logs_features.to_csv('user_logs_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camke\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 3 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Merge members and labels files\n",
    "features_all = None\n",
    "features_all = members.join(labels, how='inner')\n",
    "features_all = features_all.join(user_logs_features, how='inner')\n",
    "\n",
    "#Note, the warning is okay, and actually helps us by flattening our column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert days to integers\n",
    "#user_logs['days_before_max_date'] = (user_logs['max_date'] - user_logs['date']).apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write all features to csv\n",
    "features_all.to_csv('features_all.csv')\n",
    "features_all.to_pickle('features_all.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High level plan.  Let's try several things:\n",
    "\n",
    "* Initially get a table by user (1 row per user)\n",
    "* User most recent date (max date)\n",
    "* User first date (min date)\n",
    "* How long they've been listening:  Min vs. max date by user\n",
    "* Matrix of all the following (cartesian product)\n",
    "    * Total X=(seconds, 100, 985, 75, 50, 25, unique), avg per day of X, maybe median per day of X\n",
    "    * Last day, last 7 days, last 30 days, last 90, 180, 365, total (note last day is relative to user)\n",
    "    * % change in periods above vs. outside that period.\n",
    "    * ??? Total change in periods above vs. outside that period.\n",
    "    * ??? Variation (do they listen consistently, or is it varied)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other stuff below.  Delete for final product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sample code, for reference:       \n",
    "    #Gets # of column levels\n",
    "        #past_xdays_by_user.columns.nlevels\n",
    "    \n",
    "    #This gets only items <= 7 days old\n",
    "        #user_logs.loc[(user_logs['days_before_max_date'] <= 7)]\n",
    "\n",
    "    #Get all records from specfic user in past 45 days\n",
    "        #user_logs.loc[(user_logs['msno'] == 'aof/9XT0zVdONwrq7vd+V4y3saluJQy+Wj0dlo9TKvI=') & (user_logs['days_before_max_date'] < 45)]\n",
    "\n",
    "    #Just count songs\n",
    "        #user_logs_gb.agg({'num_unq':{'count','sum'}}).head()\n",
    "        \n",
    "    #This code resolves columns with the same name, but shouldn't be used\n",
    "        #user_logs_features = user_logs_features.join(past_xdays_by_user, lsuffix='_l', rsuffix='_r', how='inner')\n",
    "\n",
    "    #This code doesn't error but the results aren't as expected \n",
    "        # user_logs_gb.apply(lambda x: pd.Series(dict(\n",
    "        #     song_count=(x.days_before_max_date <= 7).count(),\n",
    "        #     song_sum=(x.days_before_max_date <= 7).sum()\n",
    "        # )))\n",
    "        \n",
    "#Ideas\n",
    "    #Maybe get avg. days_before_max_date ... maybe something here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

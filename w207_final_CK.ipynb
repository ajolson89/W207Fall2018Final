{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data\n",
    "members = pd.read_csv('members_filtered.csv')\n",
    "transactions = pd.read_csv('transactions_filtered.csv')\n",
    "user_logs = pd.read_csv('user_logs_filtered.csv')\n",
    "labels = pd.read_csv('labels_filtered.csv')\n",
    "\n",
    "#Set indices\n",
    "members.set_index('msno', inplace = True)\n",
    "labels.set_index('msno', inplace = True)\n",
    "\n",
    "#user_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pd_to_date(df_col):\n",
    "    df_col = pd.to_datetime(df_col, format = '%Y%m%d')\n",
    "    return df_col\n",
    "\n",
    "#Convert to date\n",
    "user_logs['date'] = pd_to_date(user_logs['date'])\n",
    "#user_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High level plan.  Let's try several things:\n",
    "\n",
    "* Initially get a table by user (1 row per user)\n",
    "* User most recent date (max date)\n",
    "* User first date (min date)\n",
    "* How long they've been listening:  Min vs. max date by user\n",
    "* Matrix of all the following (cartesian product)\n",
    "    * Total X=(seconds, 100, 985, 75, 50, 25, unique), avg per day of X, maybe median per day of X\n",
    "    * Last day, last 7 days, last 30 days, last 90, 180, 365, total (note last day is relative to user)\n",
    "    * % change in periods above vs. outside that period.\n",
    "    * ??? Total change in periods above vs. outside that period.\n",
    "    * ??? Variation (do they listen consistently, or is it varied)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create our groupby user object \n",
    "user_logs_gb = user_logs.groupby(['msno'], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This cell is slow\n",
    "\n",
    "#Append max date to every row in main table\n",
    "user_logs['max_date'] = user_logs_gb['date'].transform('max')\n",
    "user_logs['days_before_max_date'] = (user_logs['max_date'] - user_logs['date']).apply(lambda x: x.days)\n",
    "    #The .apply(lambda...  just converts it from datetime to an integer, for easier comparisons later.\n",
    "\n",
    "#Generate user's first date, last date, and tenure\n",
    "#Also, the user_logs_features table will be the primary table to return from the transactions table\n",
    "user_logs_features = (user_logs_gb\n",
    "    .agg({'date':['max', 'min', lambda x: (max(x) - min(x)).days]})  #.days converts to int\n",
    "    .rename(columns={'max': 'max_date', 'min': 'min_date','<lambda>':'listening_tenure'})\n",
    "                      )\n",
    "#Add a 3rd level, used for joining data later\n",
    "user_logs_features = pd.concat([user_logs_features], axis=1, keys=['date_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Total X=(seconds, 100, 985, 75, 50, 25, unique), avg per day of X, maybe median per day of X\n",
    "# Last day, last 7 days, last 30 days, last 90, 180, 365, total (note last day is relative to user)\n",
    "    \n",
    "for num_days in [7, 14, 31, 90, 180, 365, 999]:\n",
    "    #Create groupby object for items with x days\n",
    "    ul_gb_xdays = (user_logs.loc[(user_logs['days_before_max_date'] < num_days)]\n",
    "                   .groupby(['msno'], sort=False))\n",
    "\n",
    "    #Generate sum and mean (and count, once) for all the user logs stats\n",
    "    past_xdays_by_user = (ul_gb_xdays\n",
    "        .agg({'num_unq':['sum', 'mean', 'count'],\n",
    "              'total_secs':['sum', 'mean'],\n",
    "              'num_25':['sum', 'mean'],\n",
    "              'num_50':['sum', 'mean'],\n",
    "              'num_75':['sum', 'mean'],\n",
    "              'num_985':['sum', 'mean'],\n",
    "              'num_100':['sum', 'mean'],\n",
    "             })\n",
    "                      )\n",
    "    #Append level header\n",
    "    past_xdays_by_user = pd.concat([past_xdays_by_user], axis=1, keys=['within_days_' + str(num_days)])\n",
    "\n",
    "    #Join (append) to user_logs_features table\n",
    "    user_logs_features = user_logs_features.join(past_xdays_by_user, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next, let's look at changes in last 7 days vs. last 30 days, and last 30 days vs. last 180 days.\n",
    "\n",
    "#Also, need to think about users with < x days tenure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save to CSV\n",
    "#Now skipping this step in favor of writing the full features table to CSV below\n",
    "#user_logs_features.to_csv('user_logs_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camke\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 3 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Merge members and labels files\n",
    "features_all = None\n",
    "features_all = members.join(labels, how='inner')\n",
    "features_all = features_all.join(user_logs_features, how='inner')\n",
    "\n",
    "#Note, the warning is okay, and actually helps us by flattening our column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert days to integers\n",
    "#user_logs['days_before_max_date'] = (user_logs['max_date'] - user_logs['date']).apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write all features to csv\n",
    "features_all.to_csv('features_all.csv')\n",
    "features_all.to_pickle('features_all.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High level plan.  Let's try several things:\n",
    "\n",
    "* Initially get a table by user (1 row per user)\n",
    "* User most recent date (max date)\n",
    "* User first date (min date)\n",
    "* How long they've been listening:  Min vs. max date by user\n",
    "* Matrix of all the following (cartesian product)\n",
    "    * Total X=(seconds, 100, 985, 75, 50, 25, unique), avg per day of X, maybe median per day of X\n",
    "    * Last day, last 7 days, last 30 days, last 90, 180, 365, total (note last day is relative to user)\n",
    "    * % change in periods above vs. outside that period.\n",
    "    * ??? Total change in periods above vs. outside that period.\n",
    "    * ??? Variation (do they listen consistently, or is it varied)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other stuff below.  Delete for final product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sample code, for reference:       \n",
    "    #Gets # of column levels\n",
    "        #past_xdays_by_user.columns.nlevels\n",
    "    \n",
    "    #This gets only items <= 7 days old\n",
    "        #user_logs.loc[(user_logs['days_before_max_date'] <= 7)]\n",
    "\n",
    "    #Get all records from specfic user in past 45 days\n",
    "        #user_logs.loc[(user_logs['msno'] == 'aof/9XT0zVdONwrq7vd+V4y3saluJQy+Wj0dlo9TKvI=') & (user_logs['days_before_max_date'] < 45)]\n",
    "\n",
    "    #Just count songs\n",
    "        #user_logs_gb.agg({'num_unq':{'count','sum'}}).head()\n",
    "        \n",
    "    #This code resolves columns with the same name, but shouldn't be used\n",
    "        #user_logs_features = user_logs_features.join(past_xdays_by_user, lsuffix='_l', rsuffix='_r', how='inner')\n",
    "\n",
    "    #This code doesn't error but the results aren't as expected \n",
    "        # user_logs_gb.apply(lambda x: pd.Series(dict(\n",
    "        #     song_count=(x.days_before_max_date <= 7).count(),\n",
    "        #     song_sum=(x.days_before_max_date <= 7).sum()\n",
    "        # )))\n",
    "        \n",
    "#Ideas\n",
    "    #Maybe get avg. days_before_max_date ... maybe something here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
